# CDN了解

## 认识CDN

### 概念和产生背景

内容分发网络/内容交付网络.

互联网和万维网的区分:

- 互联网以tcp/ip为核心的网络层,是网络的基础
- 万维网www以应用为代表的应用层,是互联网中最粗的一个枝条

内容提供商sp(service provider)提供服务,用户来消费.
整个过程的优化只能发生在应用程,优化互联网很难.
目前网络传输存在4个易堵地方:

- 第一公里:sp接入互联网的带宽
- 最后一公里:用户接入互联网的带宽(现阶段4G/5G已解决这部分的瓶颈)
- 对等互联网关:不同运营商的互联互通,这是跨网问题(BGP机房少)
- 长途骨干传输:IDC/骨干网/用户城域网/用户接入网

### CDN的基本工作过程

传统访问url的过程:

- 用户将url丢给dns服务器,获取具体的ip地址
- 用户去具体的ip地址(sp)访问,获取内容

使用cdn访问url的过程:

- 用户将url丢给本地dns系统,dns会用cname记录转给cdn专用dns服务器
- cdn的dns将cdn的全局负载均衡设备ip返回给用户
- 用户将url丢给全局负载均衡设备, 设备会返回一个具体的缓存服务器
- 用户将url丢给缓存服务器,如果有,直接返回,如果没有,缓存服务器就去源站拉去数据

全局复杂均衡设备会判断用户ip(就近),
会判断url(看哪台缓存服务器有内容),
会判断各缓存服务器的负载(均衡).

## CDN技术概述

cdn的原理:

- 挑选最优设备为用户服务
- 如果某个内容被很多用户需要,将缓存到离用户最近的节点

前一点的最优是负载均衡,后一点是就近接入,为的是快速响应.

cdn的缓存服务节点很多,一般会部署在idc(因为离用户近).

### 功能架构

功能上分3块:

- 分发服务系统
	- 主要作用:源站内容推送到边缘站,并存储
	- 边缘站还负责与源站同步
	- 依据内容类型和服务种类,包含以下子服务系统
		- 网页加速子系统
		- 流媒体加速子系统
		- 应用加速子系统
		- 每个子系统都是一个独立分布式集群
- 负载均衡系统
	- 访问调度中枢,告诉用户最终的访问地址
- 运营管理系统
	- 有两个子系统,运营管理和网络管理
	- 运营管理是业务管理功能的实体
		- 负载业务层和外界的交互
		- 包括以下子系统
			- 客户管理
			- 产品管理
			- 计费管理
			- 统计分析
	- 网络管理对cdn网络资源管理/拓扑管理/链路监控/故障管理

分发服务系统,需要更新/同步内容/响应用户需求,
同时还需向上层调度控制系统提供每个缓存节点的健康状况/
响应情况以及内容分布情况,上层调度控制系统会根据这些信息计算"最优".

负载均衡系统,一般是分级实现,最简单的是两级:
gslb全局负载均衡/slb本地负载均衡.

gslb主要考虑"就近",通过dns或应用层重定向实现.
slb主要考虑"设备负载均衡",
当用户请求从gslb调度到slb时,会依据缓存节点的负载对用户进行重定向,
常用的实现有4层调度/7层调度/链路负载调度.

### 部署架构

cdn系统的第一目的:快速响应(减少用户访问时间).
离用户最近的缓存节点部署在网络的边缘位置,称边缘层.
对应的有中心层,中心层负载全局性管理和控制的设备组成,
中心层的缓存内容最多,如果边缘站未命中,会去中心站请求,
中心站也未命中,就会去源站请求(这个叫回源).

cdn越庞大,那么中心层和边缘层之间还可以加层,负载一个区域的管理和控制.

一般cdn的部署分3层.节点是最基本的部署单元,
这些节点数量巨大,地理位置分散.边缘节点称为pop点,
中心层和区域节点称为骨干点.
pop(point of persence)面向用户提供服务的节点.

一个节点包中可包含缓存设备和本地负载均衡设备slb,
缓存设备和负载均衡设备有两种连接方式:

- 穿越
	- slb有l4-7交换机实现
	- slb充当nat,屏蔽缓存设备的ip
	- 缺点是节点容量大时,l4-7容易成为瓶颈
- 旁路
	- 并联模式,缺点是安全性不够
	- 这种模式下,slb和cache是同等级的
		- 用户先访问slb,再访问cache

### cdn系统的分类

基于内容类型

- 静态网页 - 网页加速
- 动态网页 - 网页加速
- 流媒体 - 流媒体加速
	- 流媒体直播加速(p2p技术就是这种业务下的产物)
	- 流媒体点播加速
- 下载型文件 - 文件传输加速(http/ftp/p2p下载)
- 应用协议 - 应用协议加速
	- 针对tpc/ip传输协议优化,或是针对特殊协议
	- 广域网应用加速
	- ssl应用加速
	- 网页压缩

基于内容生成机制和分层(这点后续详细说到)

### 小结

cdn的三维模型:

- x, 业务类型(web/流媒体/p2p)
- y, 网页分级(中心/区域/边缘)
- z, 数据平面/管理平面/控制平面

## 内容缓存工作原理和实现

cache是基础技术和组成单元.

### cache技术的发展背景

随着用户的增长,在服务端做扩展,做集群,这些无法解决网页延时,
也无法解决"最后一公里"等网络问题,也就出现了cache技术.

先看下用户增长时,常见的问题:

- 无法及时满足并发用户增长的需求
	- 常规解决:集群
- 集群后,较远用户体验不佳
	- 常规解决:部署多个镜像
- 部署镜像后,中心和镜像同步不及时,无法智能故障迁移,成本高,易受攻击

在cdn之前,这些常规解决方案的技术如下

- 扩展 scale
	- scale up, 提升服务器性能
	- scale out, 服务器集群
- 镜像 mirroring
	- 自动备份,常用于解决跨网问题
- 缓存 cache
	- 基于缓存技术的主要应用方式有缓存代理和cdn

### cache设备的工作方式和设计要求

设备厂商研发cache设备时,不会区分web cache设备和流媒体cache设备,
但cdn服务运营提供商会区分,因为优化技术路线不同,
cdn服务提供商会推出两个独立产品.

下面只涉及web cache,流媒体cache在之后讲到.

用户的一次网页访问,会涉及4个网元:

- 用户
- 代理
- 网关
- web服务器

http规定,客户端,用户浏览器已缓存了,用户再次访问可直接使用缓存,
所以web cache一般放在代理或网关上.

web cache作为代理时,工作模式时正向代理或透明代理;
web cache放在网关是,工作模式是反向代理,这种模式也是cdn应用场景,
也是web cache应用最多的场景.

### 正向代理/反向代理/透明代理

正向代理 forward proxy:

- 用户主机和代理服务器部署在同一网络环境
- 如果代理有用户请求的缓存,就直接返回
- 多用于中小企业网络环境
	- 除了缓存,还可以提供安全认证/访问控制
- 用户主机需要配置正向代理服务

反向代理 backward proxy:

- 用户不需要配置代理服务器地址
- cache设备会写入dns记录,利用cache设备的内容路由/交互能力完成代理访问
- 多用于大型isp/icp和运营商环境
- 当cache较多时,需要部署gslb 全部负载均衡 (这也是cdn的雏形)
- 代理服务器cache和应用服务部署在同已网络环境
- 反向代理提供负载分担和安全隔离作用

idc/icp/isp区分:

- icp (internet content provider),网页内容服务商
	- 各个提供服务的公司,eg:提供网站服务的公司
- idc (internet data center),网络数据中心
	- 为icp提供托管/租用服务,常称为机房
- isp (Internetservice provider), 互联网服务提供商
	- 为网络最终用户提供接入,eg:电信 移动 联通

透明代理 transparent proxy:

- 用户浏览器不需要配置代理服务器
- 用户路由设备需要支持wccp协议(web cache control protocol)
- 不用wccp协议,也可以L4层将用户流量转给cache
- 部署和正向代理类似,但用户主机不需要配置代理服务

透明代理可以看作是通过"网络设备/协议"实现的正向代理.

实现一个web cache的关键点:

- http基本功能
- 具体应用场景和工作模式下,需要达到不同的性能指标

### web cache的实现基础

从技术上将,web架构的精华有3点:

- html,实现信息与信息的连接
- uri, 实现全球信息的精确定位
- http, 实现分布式信息共享

http工作原理:

- http基于tcp,https还会经过tls/ssl封装
- http不必担心数据丢失,也不用考虑丢失重传之后的乱序
- http是无状态的,即服务端不会存客户端请求的状态信息
	- 基于这点,http 1.0是短连接
	- 1.0 连接时的三次握手
		- client: syn
		- server: syn ack
		- client: ack
	- 1.0 接收时的消息
		- server: fin
		- client: ack
		- client: fin
		- server: ack
- http 1.1 在三次握手之后,可持续交换数据,减少了1.0的网络浪费
	- 如果http 1.1不想使用长连接,可在http头的Connection设置为close

http协议分析:

- http是标准的request-response协议
- 其他部分可参数书本

http的几个关键应用:cookie/session/安全协议/cache.

web cache缓存的原则:

- http response头,告诉cache不保存副本,cache就不缓存相应内容
- 如果亲求信息需要源站认证或涉及安全协议,相应内容就不会被缓存
- 如果缓存内容有一下信息,则认为信息是新的,不向源站重新获取:
	- 有过期时间,且没有过期
	- 缓存内容近期提供过服务,且更新时间比最近使用时间久很多
- 如果缓存内容过期,cache会向源站发送验证信息,确定内容是否还可用
- 特殊情况(eg:断网),cache内容可用
- 如果response头中不存在判断内容是否变化的值,也没有新鲜度信息,则内容通常不会被缓存

控制内容是否缓存的方法:

- html meta标签;http头信息
- http头信息中的Expires,过期时间
- 验证(http 1.1中提出的概念)
- http头信息中的缓存控制 Cache-Control
- http头信息中的通用头,Pragma

### web cache 关键性能指标

这些性能指标是依据具体场景和用户规模而定.

- 并发量
	- 超过预期值后,采用虚拟排队等方式限制用户访问数量
- 吞吐量
	- 除了cache cpu有影响,还有网络带宽,应用协议有关
- 命中率
	- 是判断cdn优劣的重要指标
	- web cache一般在30-60%
- 响应时间和丢包率
	- dns解析时间,0.18-.03秒,小于0.18为优秀
	- 建立连接时间,0.15-0.3秒
	- 重定向时间,小于0.1秒
	- 收到第一个包时间,0.2-0.4秒
	- 图片下载时间, 150k的图片,1-2秒
	- 页面总下载时间, 10秒内
	- 丢包率, 会影响响应时间

### 内容存储机制

这个机制直接影响web cache的命中率/响应速度/投资成本.

从存储类型看,关注容量/成本/服务性能:

- 容量越大,可缓存内容越多,命中率越高
- 成本越低,服务附加值越高,竞争力越高
- 缓存内容大小越小,数量就越多,web cache一般是10-12k

常见的存储技术方案:

- 共享存储
	- 设备性能好,稳定,可靠
	- 成本高
- 本地附加存储 DAS
	- 适合web cache
- 分布式文件系统服务
	- 大容量,高性能,高可靠
	- 对部署实施技术要求高
	- 可能引入网络延时,更适合流媒体服务

从内容管理技术看,关注目录组织方式和管理方式,
目录层级越少,检索时间越小.

### 内容更新机制

更新机制涉及两个部分:哪些内容需要缓存;缓存内容如何更新.

web cache会遵循以下规则:

- 如果http响应头告诉cache不要缓存,就不缓存
- 如果某些请求需要认证或安全加密,cache不会缓存
- 如果http响应中没有ETag/Last-Modified,cache默认不缓存
- 如果一个缓存副本包含以下内容,就认为足够新鲜
	- 有过期时间,且没过期
	- 浏览器已经使用过这个缓存副本,且在同一个会话中检测了新鲜度
- 如果缓存副本旧了,cache会向源站验证,可用就继续用,不可用就从源站拉取

一般静态资源会被缓存(html/图片/js/css/xml),
动态资源不会被缓存(动态地址/asp/aspx/py/jsp/php).

### web cache 协议优化

- http协议实施优化
	- http连接聚合(把多个短连接转换成一个长连接)
	- http gzip压缩
- 基于tcp传输优化

### web cache 安全实现机制

- 访问控制
	- 运行访问控制列表ACL,不在列表中的ip会被拒绝
	- ACL可指定拒绝某个ip用户
	- ACL可屏蔽指定站点/域名/url,屏蔽之后,用户无法访问
	- 限制内容用户访问外网的时间
	- 赋予某些用户特殊访问权限,eg:管理员
	- 控制访问外网服务器的端口号
	- 其他功能,eg:减缓或加速内容发送,用户身份认证
	- 防止网络攻击
- 病毒防护
- 网络安全防护
- 内容加密

### 开源web cache: squid

一个使用非常广泛的web cache,有以下特点:

- web代理
- 内容缓存和加速
- ACL访问控制
- 用户认证
- 日志

## 集群和负载均衡

### 集群的基本概念

一台cache无法满足需求时,就需要一组服务器来提供服务.

集群的特点:

- 将彼此独立的服务器通过高速网络连接在一起
- 形成一个并行或分布式系统
- 服务器上运行一系列共同程序
- 对外提供单一系统映射,提供一个服务

相对单台服务器:

- 提高性能(提高了算力)
- 降低成本
- 提高可扩展性(节点数可控)
- 增强可用性(负载均衡/容错备援/故障切换/故障迁移)

依据集群用途的不同,集群可分以下几类:

- 计算集群
- 负载均衡集群
- 高可用集群

CDN可归类为负载均衡集群.

集群的系统结构主要分4个层次:

- 网络层(网络互联结构/通信协议/信号传输技术)
- 节点服务器操作系统层 (高性能服务器架构/高性能操作系统内核技术)
- 应用层 (并行程序开发环境/各类解决任务负载的串/并行应用)
- 集群管理系统层

对于cdn集群来说,各台服务器知道彼此内容缓存的情况非常重要,
所以内部协同交互的方法非常重要.这些方法分两大类:

- 松耦合
	- 通信协议:icp/htcp/cache digest/ cache pre-filling
- 紧耦合
	- 通信协议:carp

### 协同交互协议

ICP, internet cache protocol,互联网缓存协议,
一般基于udp使用,不包含http头,也存在cache失效的情况.

HTCP, hypertext caching protocol, 超文本缓存协议,
带http头.不用密码认证易受到攻击.

cache digest,为了解决icp/htcp的网络延时和拥塞问题.
每个cache都保存其他邻居的所有缓存信息摘要.

cache pre-filling,是一种推送缓存内容的机制.

carp, cache array routing protocol,分布式缓存协议.
有个hash算法可以准备定位服务器阵列中的缓存内容

### 负载均衡

server load balance, 负载均衡.

依据目的,负载均衡分两种:

- 任务分担
- 协同计算

负载均衡之前以OSI七层网络协议栈的第4层展开,
现在主要以第七层展开. L4-7.

负载均衡关键技术:

- 负载均衡调度算法
	- 静态算法
		- 轮询
		- 加权轮询
		- 随机
		- 加权随机
		- 基于源ip的hash
		- 基于源ip端口的hash
		- 基于目的ip的hash
		- 基于udp报文payload的hash
	- 动态算法
		- 基于最小连接
		- 就加权最小连接
		- 最小响应时间
- 会话连续性保持
	- 基于源ip地址的连续性保持
	- 基于cookie数据的连续性保持
	- 基于sip报文call-id的连续性保持
	- 基于http报文头的连续性保持
- 服务器健康检测
	- ICMP
	- TCP
	- HTTP
	- FTP
	- DNS
	- RADIUS
	- SSL

### 负载均衡部署方式

负载均衡设备的部署方式有两种:

- 直连
- 旁挂

此外为了提高可用性,双机热备十分有必要.

双机热备分两种类型:

- 主备模式
- 负载分担模式

### 服务器负载均衡

L4/L7,L4基于流,L7基于内容.

L4负载均衡的实现有两种:NAT/DR.

基于NAT方式的L4负载均衡,主要组件如下:

- 负载均衡设备
- 真实服务器
- 虚拟ip地址
- 服务器ip地址

特色是对服务器没有额外要求,不需要修改服务器配置.

基于DR方式的L4负载均衡,服务端返回的响应不需要经过负载均衡设备.
负载均衡设备是以旁挂形式和交换机相连.
真实服务也有一个虚拟ip,响应返回时,真实服务器直接丢给交换机,
响应的源地址是虚拟ip地址,这个ip地址还不接收arp请求.

L4负载均衡只关心ip报文头和tcp/udp报文头,对payload不关心,
L7除了关心L4所关心的数据,还关心4层以上的数据,
L7会解析http内容,会关心http的url和cookie.

L7相对L4有以下优点:

- 可根据数据包内容,把流量引入相应服务器,提高管理性和灵活性
- 根据请求的数据类型,引入不相应服务器,提高性能改善安全性
- 根据应用层payload保证会话持续性.

基于NAT的L7负载均衡和L4类似,只是多了一个服务器组的概念.

### 链路负载均衡

通过动态算法在多条网络链路中进行负载均衡.

在使用多个isp时才考虑这种情况.

OutBound链路解决企业内部业务系统访问外部互联网;
Inbound链路解决互联网外部用户如何访问企业内部网站和业务系统.

OutBound链路负载均衡包含如下主要组件:

- 负载均衡设备
- 物理链路,由isp提供
- 虚拟ip地址(负载均衡器对外提供的虚拟地址)

特点:

- 结合NAT技术进行组网,不同链路使用不同的源ip地址
- 通过健康性检查,有效保证整条路劲的可达性
- 通过负载均衡调度算法,可在多条链路见均衡流量

### 开源负载均衡软件

L4的LVS,L7的Nginx.

负载均衡系统通常位于整个集群的最前端,由一台或多台负载调度器组成.

LVS支持nat/tun/dr实现方式.主要特点如下:

- 性能好
- 配置简单
- 工作稳定

Nginx时高性能http和反向代理服务器.主要特点如下:

- 调度灵活
- 网络依赖性低
- 支持服务器检测

## 全局负载均衡工作原理和实现

全局负载均衡gslb是针对多数据中心(多机房)的场景.
gslb常用实现是基于dns的.因为dns有域名解析/就近性判断/轮询算法.

### 基于DNS的gslb

DNS是一个应用层协议,常被应用层的其他协议所使用.

DNS说明:

- 域名解析是在http会话之前完成的
- 域名空间,是一个倒置的树,最上面是根,共13个根
- 根下有7个顶级域tld, top level domain
	- com 商业组织
	- edu 教育机构
	- gov 政府部门
	- mil 军事部门
	- net 网络基础设施
	- org 非营利组织
	- int 国际组织
- 除了通用的7个顶级域,每个国家都有各自的顶级域(eg:cn)
- 顶级域向下是分支域(eg:baidu.com),每一个域都是一个子树
- 每个域中,会有一台/多台服务器用来保存域名空间的所有信息
	- 这个叫权威域名服务器,也叫授权域服务器
	- 权威域名服务器有这个域所有的域名信息
	- 一个域最多有一个主域名服务器
- 用户所在局域网或isp网络中的域名服务器称本地dns服务器ldns
	- 用户请求都会先去查ldns,再去查dns服务器

dns的查询分递归查询方式和迭代查询方式.

dns系统最常见的是internet类记录,记录包含4个元组:

- Name
- Value
- Type
- TTL

记录的Type有以下几种:

- A记录,address
	- 域名到ip的映射关系,这是1对多的关系
- NS记录,name server
	- 域名服务器的记录,指定该域名由哪个dns服务器来解析
- SOA记录,start of authority
	- 指定该区域权威域名服务器,只有一个,而且是资源记录的第一条
- CNAME记录
	- 别名和域名的对应关系
		- 一般会先通过CNAME记录,将别名替换为域名或主机名
		- 再通过A记录来获取相应的ip地址
- PRT记录,pointor record
	- 描述ip地址到域名的映射关系
	- 这是特别域,你想解析域

### 基于dns解析的gslb工作方式

用户发送任何连接请求,都会先通过dns获取服务器ip,
基于dns的gslb就是将负载均衡器部署在dns系统中,
在dns解析结果返回的过程中,进行智能决策,
给用户返回一个最优ip.

具体的实现方式如下:

- 通过CNAME方式实现负载均衡
	- 将gslb主机名定义为所查域名的权威dns服务器别名
	- 为gslb主机名添加多条A记录,分别对应多个实际服务器ip
	- 这种方式利用了dns的别名机制和轮询机制
- 将负载均衡器作为权威dns服务器
	- 负载均衡器会接收对这个域的所有dns请求
	- 之后再执行智能dns解析
- 将负载均衡器作为代理dns服务器
	- 将负载均衡器注册为权威dns服务器
	- 真正的权威dns服务器再负载均衡器之后

### 负载均衡的策略判断

策略判断是基于以下信息而来:

- 服务器的"健康状况"
	- 监控服务器的健康状况是gslb的最重要特性之一
- 地理区域距离
	- 本地dns服务器ip到服务器ip的路由距离
- 会话保持
- 响应时间
	- 是指cdn集群最优时间,应该选一段时间的平均值
- ip地址权重
- 会话能力阈值
- 往返时间rtt
- 其他信息
	- 服务器当前可用会话数
	- 最小选择次数
	- 轮询

开源dns服务软件:bind

### 基于dns的gslb部署时的概念

cdn使用gslb时的概念:

- 域组 domain group
- 服务池 pool
- 虚拟服务器 virtual server
- 区域 region
- 策略

### 负载均衡策略

策略分静态和动态.

静态策略:

- 基于特定的用户源ip地址
	- 将特定ip地址定向到指定pop节点
- 基于加权ip地址
	- 给服务池中的虚拟服务器的ip分配权值
	- 权值越高,越容易被选中
	- 适用于服务器性能有差异的场景
- 基于加权pop节点
	- 和加权ip类似
	- 加权ip针对逻辑上的虚拟服务器
	- 加权pop针对物理节点
- 基于地址位置
	- 就近
- 基于pop节点管理优先级
- 基于简单轮询
	- 最简单,也是dns最常用的负载均衡方式
- 基于成本
	- 不同的isp收费不同

静态策略,调度效率高,但没考虑实际场景,可能不准确.
动态策略会根据网络和服务器资源是的实时情况调整.

- 基于pop节点健康状况
- 基于相对会话能力
	- 当前会话数/最大会话数反映了当前负载/最大负载
- 基于绝对会话能力
- 基于物理服务器绑定
- 基于主动测量的用户访问往返时间rtt
- 基于被动测量的用户访问往返时间rtt
- 基于新建连接数(适合web访问的负载均衡)
- 基于流量(适合访问流媒体内容的调度)
- 基于pop节点访问次数

例子,基于流量负载均衡的例子:

基于负反馈原理,控制系统根据系统输出和预期之间的偏差,
来对系统加以控制.具体算法如下:

- 第一步
	- 在提供服务之前,gslb通过网管配置获取pop的信息
	- 节点i最大服务带宽为Bi
	- 所有节点最大服务带宽为Bsum
	- gslb计算每个节点的期望负载 Ri,B= Bi/Bsum
- 第二步
	- 每个pop节点周期性向gslb上报自己的流量信息
	- gslb用Ti表示节点i的流量
	- gslb用Tsum表示所有节点的流量
	- 计算每个节点的实际负载 Ri,T = Ti/Tsum
	- 用实际负载减期望负载 Di = Ri,T - Ri,B
		- Di大于0,表示实际大于期望,需要减少i节点的流量分
		- 反之,需要增大分配
- 第三步
	- gslb根据Di大小设置一个权重值Wi,Di越小,权值越大
	- 权值Wi越大表示实际负载远小于预期负载
- 第四步
	- gslb根据权值Wi的大小成比例引入流量
	- Di时差异量,Wi是控制量
- 第五步
	- gslb不断计算Di值,不断修改Wi
	- 使各节点总是处于一个长期的平稳状态

Di和Wi的映射关系是一个复杂过程,
好的实现体现在收敛时间有多短.

例子,基于rtt和流量的负载均衡的例子:

- 第一步
	- 用户通过主动/被动测量定期获取每个ip子网到节点的rtt
	- ds,i表示子网s到节点i的rtt
	- 同时用户会定期获取每个节点的Di(Di见上个算法)
- 第二步
	- 当子网s的用户发起请求,gslb比较子网s到节点的rtt(ds,i)
	- 先剔除ds,i超过阈值的节点,剩下节点可提供服务
	- 用户选择ds,i最小的节点作为默认节点,其他节点作为备选
- 第三步
	- 子网s的用户发起请求,gslb先检测默认节点
		- 当默认节点达到最大服务带宽Bi,将请求平均引入其他备用节点
		- 若默认节点流量未到达Bi
			- 默认节点Di小于某个阈值,流量引入默认节点
			- 默认节点Di在某个阈值范围
				- 按概率将流量引入默认节点
				- 没有引入默认节点的流量平均分配到备选节点
			- 默认节点Di大于某个阈值
				- 按概率将流量引入默认节点,这个概率会更小
- 第四步
	- gslb不断计算各节点的Di以及各子网到它的ds,i
	- 这样动态修改调度策略

### gslb部署中的关键问题

cdn有自建的,也有sp提供的.自建的可管控性高,
sp更多是自己业务的扩展,这里的sp指公司或运营商.
sp也可以租用cdn.

- 网站sp
	- sp要求cdn提供全网加速
		- gslb应该识别所有用户所属区域
	- sp要求cdn提供部分区域加速
		- 用户源由sp控制
		- gslb识别此预取的用户
	- sp要求cdn提供部分区域加速,也要求gsbl提供权威dns服务
		- sp不用控制用户源
		- gslb应该识别所有用户所属区域
			- 只为一定区域用户提供加速服务
			- 针对其他的用户,提供sp源域名授权解析服务
- 用户访问调度
- 异常流程
	- 基于dns方式的gslb只能完成就近性判断
	- 常在gslb设备以旁路的方式部署一个辅助设备
		- 这个辅助设备是GRM,全局资源管理设备
		- GRM和各pop的本地资源管理设备LRM通信
		- GRM和LRM完成对pop状态检查,流量情况
		- GRM定期会通过LRM采集pop的流量/并发信息
		- GRM会根据实际和预期信息,更新调度策略,下发给gslb
	- slb/GRM/LRM相互通信易出现以下异常
		- pop节点上的lrm设备故障
		- pop节点的slb设备故障
- 网络攻击

### 基于应用层协议重定向的gslb

和基于dns不同,这里说的是利用http/mms/rtsp协议本身的重定向实现的gsbl.

### 基于ip路由的gslb

这里利用的是路由器本身的路由算法和数据包转发能力.

这种方式多用于IGP协议(城域网),很难用于BGP协议进行跨网负载均衡.

lisp协议理论上可用于glsb,但目前还不成熟.

## 流媒体CDN系统的组成和核心技术

常见的流媒体传输协议包括:

- rtsp 实时流传输协议
- rtp/rtcp 实时传输协议/实时传输控制协议
- rtmp 实时消息传输协议
- http流化协议

rtp的任务就是提供时间信息和实现流同步.
rtcp负责在会话参与者之间交换控制信息,
因为rtp只负责流媒体数据包的交付.

基于http的有渐进式下载,现在多为http流化方式.

流化方式目前有:

- apple的hls
- 3gpp的ahs
- 微软的iis smooth streaming (是基于ahs发展的)
- adobe的http dynamic streaming

流媒体的特点是:实时/连续/时序.

### 流媒体cdn系统架构

主要组件包括:

- 管理支撑子系统
	- 网络管理系统
		- 拓扑管理
		- 节点管理
		- 配置管理
		- 故障管理
		- 性能管理
		- 网络安全管理
	- 运营管理
		- 客户管理
		- 客户自服务实现
		- 产品/业务能力管理
		- 工单管理
		- 认证管理
		- 计费/结算管理
	- 统计分析
		- 日志管理
		- 数据筛选/分析
		- 报表生成
	- 业务接口,负责和其他系统的接口适配
		- 其他系统包括(boss系统/门户系统/并向sp自助服务)
- 负载均衡子系统
	- 命中成为首要考虑因素
	- 热点内容要预先push
- 内容管理子系统
	- 对热内容进行预处理
	- 保证冷热分布合理
- 流媒体服务子系统

### 流媒体cdn关键技术的实现

cache设计:

- 协议上以rtsp/rtmp为主
	- 命中就提供,未命中就去源站拉取,过程也是边拉变提供给用户
	- cache作为流媒体服务器的代理,也是能进行协议转换的
	- 做好流媒体cache的关键在于对各种协议的理解/扩展/优化
- 缓存算法
	- 替换算法
		- 决定cache性能的核心因素
		- 传统的有lfu/lru/lru-threshold
		- 针对流媒体的有rbc 资源缓存算法
		- 还有针对分层编码的缓存替换算法
	- 预取算法
		- cache向父cache预取算法
		- cache和用户之间的预取算法
		- rejaie设计的基于滑动窗口预取算法
		- fan设计的预推算法
	- 前缀缓存算法
		- 用户对秒开相当敏感,可将内容的开头进行缓存
- 存储设计
	- web cache需求是 小文件/高并发,消耗的是cpu
	- 流媒体cdn的cache,需求是 大文件持续读,对磁盘io要求大
	- 磁盘io的优化常用以下方法
		- 磁盘区域算法
		- 分块和交错算法
	- 常见的分布式存储技术包括
		- 分布式文件系统
		- 分布式数据库

### 负载均衡系统设计的实现

gslb/slb都会优先考虑命中率.因为回源压力大,成本高.
流媒体cdn大多选用基于http重定向的方式,
也可以选择和dns方式结合.

基于增益模型的服务器选择算法,增益包含两部分:

- 用户增益: 用户接收媒体获得直接增益
- 网络利用率增益:避免网络资源过多消耗而获得的间接增益

### 内容分发机制实现

内容分发是内容从中心节点到各个区域/边缘节点的分发.

实现方式有pull/push两种方式.
pull是下拉方式,由用户请求驱动;
push是主动推送方式,通常由内容管理系统发起.
pull适合内容访问分散的情况,push适合访问比较集中的情况.

### 流媒体cdn的组网模式

web cdn通常是两级架构(中心/边缘),
流媒体cdn基本都是三级以上的架构(中心/区域/边缘).
主要是因为回源成本太高.

分层部署的意义:
对点播业务,在于节省存储成本;
对直播业务,在于减少带宽成本.

cache离用户越近,服务质量越好,但覆盖用户越少.

### 内容文件预处理技术

预处理的目的:

- 为内容提供一个guid
- 切片来提高服务效率,减低成本
- 满足某些业务要求,eg:同一内容的多码率输出;3屏互动

视频转码:码率/帧率/分辨率/格式.
文件切片:是p2p系统提出的技术,好处是可以从多个peer端获取内容.

svc文件切片分层编码也属于文件切片.